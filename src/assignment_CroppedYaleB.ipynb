{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMP5328 - Advanced Machine Learning\n",
    "## Assignment 1: Non-negative Matrix Factorization\n",
    "----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Semester 2, 2020)**\n",
    "\n",
    "In this ipython notebook, we provide some example code for assignment1.\n",
    "+ Load Data.\n",
    "    - ORL dataset. \n",
    "    - Extended YaleB dataset. \n",
    "    - AR dataset (**optional**).\n",
    "+ Perform Evaluation. \n",
    "   - Relative Reconstruction Errors.\n",
    "   - Accuracy, NMI (**optional**).\n",
    "\n",
    "Lecturer: Tongliang Liu.\n",
    "\n",
    "Tutors: Nicholas James, Songhua Wu, Xuefeng Li, Yu Yao.\n",
    "\n",
    "**Note: All datasets can be used only for this assignment and you are not allowed to distribute these datasets. If you want to use AR dataset, you need to apply it by yourself (we do not provide AR dataset due to the problem of license, please find more details in http://www2.ece.ohio-state.edu/~aleix/ARdatabase.html).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload for modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Define your functions in organised individual python files. Don't throw them randomly in the notebook\n",
    "\n",
    "## Import image processing modules\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd # Used for simpler processing of data\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "\n",
    "## Import Algorithms\n",
    "from algs import NmfHyperEstimator, NmfL2Estimator, ModifiedNMF, NmfL1Estimator\n",
    "\n",
    "#Import preprocessing\n",
    "from preprocessing import SaltNPepper, Gaussian, ImageNormalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset\n",
    "\n",
    "### 1.0 Data Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The structure of data folder.\n",
    "!ls -l data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Tree structure of data folder.\n",
    "├── CroppedAR\n",
    "    ├── M-001-01.bmp\n",
    "    ├── M-001-01.txt\n",
    "    ├── M-001-02.bmp\n",
    "    ├── M-001-02.txt\n",
    "    ├── ...\n",
    "├── CroppedYaleB\n",
    "│   ├── yaleB01\n",
    "│   ├── yaleB02\n",
    "│   ...\n",
    "│   ├── yaleB38\n",
    "│   └── yaleB39\n",
    "└── ORL\n",
    "    ├── s1\n",
    "    ├── s2\n",
    "    ├── s3\n",
    "    ├── ...\n",
    "    ├── s40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load ORL Dataset and Extended YaleB Dataset.\n",
    "+ ORL dataset contains ten different images of each of 40 distinct subjects. For some subjects, the images were taken at different times, varying the lighting, facial expressions (open / closed eyes, smiling / not smiling) and facial details (glasses / no glasses). All the images were taken against a dark homogeneous background with the subjects in an upright, frontal position (with tolerance for some side movement). The size of each image is 92x112 pixels, with 256 grey levels per pixel. To further reduce the computation complexity, you can resize all images to 30x37 pixels.\n",
    "\n",
    "+ Extended YaleB dataset contains 2414 images of 38 human subjects under 9 poses and 64 illumination conditions. All images are manually aligned, cropped, and then resized to 168x192 pixels. To further reduce the computation complexity, you can resize all images to 42x48 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load Extended YaleB dataset.\n",
    "X_yaleb, Y_yaleb = load_data(root='data/CroppedYaleB', reduce=4)\n",
    "print('Extended YalB dataset: X.shape = {}, Y.shape = {}'.format(X_yaleb.shape, Y_yaleb.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluation Metrics\n",
    "\n",
    "\n",
    "### 2.1 Relative Reconstruction Errors (RRE)\n",
    "\n",
    "To compare the robustness of different NMF algorithms, you can use the ```relative reconstruction errors```. Let $V$ denote the contaminated dataset (by adding noise), and $\\hat{V}$\n",
    " denote the clean dataset. Let $W$ and $H$ denote the factorization results on $V$, the ``relative reconstruction errors`` then can be defined as follows:\n",
    " \\begin{equation}\n",
    "    RRE = \\frac{ \\| \\hat{V} - WH \\|_F }{ \\| \\hat{V} \\|_F}.\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Demonstrate noisy Image\n",
    "V_hat, Y_hat = load_data(root='data/CroppedYaleB', reduce=4)\n",
    "scaler = ImageNormalizer(min=None, max=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = SaltNPepper(p=0.1, r=0.4) \n",
    "\n",
    "V_snp = noise.fit_transform(V_hat)\n",
    "V_snp = scaler.fit_transform(V_snp)\n",
    "\n",
    "noise_g = Gaussian(mean=0, sigma=10) \n",
    "V_g = noise_g.fit_transform(V_hat)\n",
    "V_g = scaler.fit_transform(V_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot result.\n",
    "img_size = [i//4 for i in (168, 192)]\n",
    "ind = 2 # index of demo image.\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.subplot(131)\n",
    "plt.imshow(V_hat[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image(Original)')\n",
    "plt.subplot(132)\n",
    "plt.imshow(V_snp[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image(snp Noise) p=0.1 r=0.4')\n",
    "plt.subplot(133)\n",
    "plt.imshow(V_g[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image(Gaussian noise) mean=0 sd=10')\n",
    "plt.draw()\n",
    "plt.savefig(\"noisyImage\", dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Reconstruction\n",
    "#Using Hypersurface\n",
    "np.random.seed(0)\n",
    "nmf_hyper = NmfHyperEstimator(n_components=50) # set n_components to num_classes.\n",
    "#Salt n Pepper\n",
    "H = nmf_hyper.fit_transform(V_snp)\n",
    "W = nmf_hyper.components_\n",
    "V_snp_reconstructed_hyper = W @ H\n",
    "#Gaussian\n",
    "H = nmf_hyper.fit_transform(V_g)\n",
    "V_g_reconstructed_hyper = W @ H\n",
    "\n",
    "#Using L2NMF\n",
    "np.random.seed(0)\n",
    "nmf_L2 = NmfL2Estimator(n_components=50) # set n_components to num_classes.\n",
    "#SaltNPepper\n",
    "H = nmf_L2.fit_transform(V_snp)\n",
    "W = nmf_L2.components_\n",
    "V_snp_reconstructed_L2 = W @ H\n",
    "#Gaussian\n",
    "H = nmf_L2.fit_transform(V_g)\n",
    "V_g_reconstructed_L2 = W @ H\n",
    "\n",
    "#Using L1NMF\n",
    "np.random.seed(0)\n",
    "nmf_L1 = NmfL1Estimator(n_components=50) # set n_components to num_classes.\n",
    "#SaltNPepper\n",
    "H = nmf_L1.fit_transform(V_snp)\n",
    "W = nmf_L1.components_\n",
    "V_snp_reconstructed_L1 = W @ H\n",
    "#Gaussian\n",
    "H = nmf_L1.fit_transform(V_g)\n",
    "V_g_reconstructed_L1 = W @ H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reconstruction (snp noise) using hyper\n",
    "img_size = [i//4 for i in (168, 192)]\n",
    "ind = 2 # index of demo image.\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.subplot(131)\n",
    "plt.imshow(V_hat[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image (Original)')\n",
    "plt.subplot(132)\n",
    "plt.imshow(V_snp[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image (snp Noise) p=0.1 r=0.4')\n",
    "plt.subplot(133)\n",
    "plt.imshow(V_snp_reconstructed_hyper[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image Reconstructed (Hyper')\n",
    "plt.savefig(\"reconstructedHyper_snp.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reconstruction (Gaussian noise) using hyper\n",
    "img_size = [i//4 for i in (168, 192)]\n",
    "ind = 2 # index of demo image.\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.subplot(131)\n",
    "plt.imshow(V_hat[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image (Original)')\n",
    "plt.subplot(132)\n",
    "plt.imshow(V_g[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image (Gaussian noise) mean=0, sd=10')\n",
    "plt.subplot(133)\n",
    "plt.imshow(V_g_reconstructed_hyper[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image Reconstructed (Hyper')\n",
    "plt.savefig(\"reconstructedHyper_gaussian\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reconstruction (snp noise) using L2NMF\n",
    "img_size = [i//4 for i in (168, 192)]\n",
    "ind = 2 # index of demo image.\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(131)\n",
    "plt.imshow(V_hat[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image (Original)')\n",
    "plt.subplot(132)\n",
    "plt.imshow(V_snp[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image (snp Noise) p=0.1 r=0.4')\n",
    "plt.subplot(133)\n",
    "plt.imshow(V_snp_reconstructed_L2[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image Reconstructed (L2)')\n",
    "plt.savefig(\"reconstructedL2_snp\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reconstruction (Gaussian noise) using L2NMF\n",
    "img_size = [i//4 for i in (168, 192)]\n",
    "ind = 2 # index of demo image.\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(131)\n",
    "plt.imshow(V_hat[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image (Original)')\n",
    "plt.subplot(132)\n",
    "plt.imshow(V_g[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image(Gaussian noise) mean=0, sd=10')\n",
    "plt.subplot(133)\n",
    "plt.imshow(V_g_reconstructed_L2[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image Reconstructed (L2)')\n",
    "plt.savefig(\"reconstructedL2_gaussian\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reconstruction (snp noise) using L1NMF\n",
    "img_size = [i//4 for i in (168, 192)]\n",
    "ind = 2 # index of demo image.\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(131)\n",
    "plt.imshow(V_hat[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image (Original)')\n",
    "plt.subplot(132)\n",
    "plt.imshow(V_snp[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image (snp Noise) p=0.1 r=0.4')\n",
    "plt.subplot(133)\n",
    "plt.imshow(V_snp_reconstructed_L1[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image Reconstructed (L1)')\n",
    "plt.savefig(\"reconstructedL1_snp\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reconstruction (Gaussian noise) using L2NMF\n",
    "img_size = [i//4 for i in (168, 192)]\n",
    "ind = 2 # index of demo image.\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(131)\n",
    "plt.imshow(V_hat[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image (Original)')\n",
    "plt.subplot(132)\n",
    "plt.imshow(V_g[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image(Gaussian noise) mean=0, sd=10')\n",
    "plt.subplot(133)\n",
    "plt.imshow(V_g_reconstructed_L1[:,ind].reshape(img_size[1],img_size[0]), cmap=plt.cm.gray)\n",
    "plt.title('Image Reconstructed (L1)')\n",
    "plt.savefig(\"reconstructedL1_gaussian\", dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Evaluate Clustering Performance\n",
    "\n",
    "1. Accuracy.\n",
    "    \n",
    "    $$ Acc(Y, Y_{pred}) = \\frac{1}{n}\\sum\\limits_{i=1}^n 1\\{Y_{pred}(i) == Y(i)\\}$$\n",
    "        \n",
    "2. Normalized Mutual Information (NMI).\n",
    "\n",
    "    $$ NMI(Y, Y_{pred}) = \\frac{2 * I(Y, Y_{pred})}{H(Y) + H(Y_{pred})} $$\n",
    "    \n",
    "   where $ I(\\cdot,\\cdot) $ is mutual information and $ H(\\cdot) $ is entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance comparison using Salt and Pepper noise (with scaling) with 90% samples (3 shuffles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, scaler = X_yaleb, Y_yaleb, ImageNormalizer(min=None,max=None)\n",
    "\n",
    "alg_kwargs_pairs = [\n",
    "    ModifiedNMF, \n",
    "    NmfL2Estimator, \n",
    "    NmfHyperEstimator,\n",
    "    NmfL1Estimator\n",
    "]\n",
    "\n",
    "metrics = [rre_score, acc_score, nmi_score]\n",
    "metrics_names = [\"rre\", \"acc_score\", \"nmi_score\"]\n",
    "n_trials = 3\n",
    "pc_sample = 0.9\n",
    "\n",
    "#Saltnpepper noise\n",
    "all_n_components = [50]\n",
    "noise_alg = SaltNPepper\n",
    "noise_levels = np.arange(0, 0.7, 0.1)\n",
    "ratios = [0.5] #np.arange(0.0, 1, 0.5)\n",
    "noise_kwargs_pairs = make_grid_alg_kwargs(noise_alg, p=noise_levels, r=ratios)\n",
    "\n",
    "evaluations_snp = benchmark(X_yaleb, Y_yaleb, scaler,\n",
    "                        alg_kwargs_pairs, all_n_components,\n",
    "                        noise_kwargs_pairs,\n",
    "                        metrics, metrics_names,\n",
    "                        n_trials, pc_sample\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations_snp_mean = evaluations_snp.groupby(['alg','n_components','noise_id']).mean()\n",
    "evaluationss_snp_mean = evaluations_snp_mean.rename(columns={'rre':'rre_mean','acc_score':'acc_mean','nmi_score':'nmi_mean'})\n",
    "evaluations_snp_std = evaluations_snp.groupby(['alg','n_components','noise_id']).std()\n",
    "evaluations_snp_std = evaluations_snp_std.rename(columns={'rre':'rre_sd','acc_score':'acc_sd','nmi_score':'nmi_sd'})\n",
    "evaluations_snp_std = evaluations_snp_std.drop(columns=['p', 'r'])\n",
    "evaluations_snp_grouped = pd.concat([evaluations_snp_mean, evaluations_snp_std],axis=1)\n",
    "evaluations_snp_grouped.to_csv('Performance_snp_scaled_90%.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting RRE, Accuracy and NMI scores against different Salt & pepper noise levels for n_components=50\n",
    "fig = plt.figure(figsize=[9, 12])\n",
    "\n",
    "ax = fig.add_subplot(311)\n",
    "sns.lineplot(\n",
    "    x=\"p\",\n",
    "    y=\"rre\",\n",
    "    hue=\"alg\",\n",
    "    #size=\"n_components\",\n",
    "    style=\"alg\",\n",
    "    data=evaluations_snp_grouped.query(\"n_components == 50 and (alg=='NmfL2Estimator' or alg=='NmfHyperEstimator' or alg=='NmfL1Estimator')\"),\n",
    "    estimator='mean',\n",
    "    ci=95,\n",
    "    n_boot=1000,\n",
    "    markers=True,\n",
    "    seed=None,\n",
    "    sort=True,\n",
    "    err_style='band',\n",
    "    #legend='full',\n",
    ")\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel(\"Relative Reconstruction Error\")\n",
    "#ax.legend(title=\"Algorithm\", loc=\"upper left\", labels=['NMF (sklearn)','L2-NMF','Hypersurface'])\n",
    "\n",
    "ax = fig.add_subplot(312)\n",
    "sns.lineplot(\n",
    "    x=\"p\",\n",
    "    y=\"acc_score\",\n",
    "    hue=\"alg\",\n",
    "    #size=\"n_components\",\n",
    "    style=\"alg\",\n",
    "    data=evaluations_snp_grouped.query(\"n_components == 50 and (alg=='NmfL2Estimator' or alg=='NmfHyperEstimator' or alg=='NmfL1Estimator')\"),\n",
    "    estimator='mean',\n",
    "    ci=95,\n",
    "    n_boot=1000,\n",
    "    markers=True,\n",
    "    seed=None,\n",
    "    sort=True,\n",
    "    err_style='band',\n",
    "    legend='full',\n",
    ")\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel(\"Accuracy Score\")\n",
    "#ax.legend(title=\"Algorithm\", loc=\"upper right\", labels=['NMF (sklearn)','L2-NMF','Hypersurface'])\n",
    "\n",
    "ax = fig.add_subplot(313)\n",
    "sns.lineplot(\n",
    "    x=\"p\",\n",
    "    y=\"nmi_score\",\n",
    "    hue=\"alg\",\n",
    "    #size=\"n_components\",\n",
    "    style=\"alg\",\n",
    "    data=evaluations_snp_grouped.query(\"n_components == 50 and (alg=='NmfL2Estimator' or alg=='NmfHyperEstimator' or alg=='NmfL1Estimator')\"),\n",
    "    estimator='mean',\n",
    "    ci=95,\n",
    "    markers=True,\n",
    "    n_boot=1000,\n",
    "    seed=None,\n",
    "    sort=True,\n",
    "    err_style='band',\n",
    "    legend='full',\n",
    ")\n",
    "ax.set_xlabel(\"Noise level\")\n",
    "ax.set_ylabel(\"Normalised Mutual Info Score\")\n",
    "#ax.legend(title=\"Algorithm\", loc=\"upper right\", labels=['NMF (sklearn)','L2-NMF','Hypersurface'])\n",
    "plt.suptitle(\"Model performances with Salt and pepper noise (using 50 components)\")\n",
    "plt.savefig(\"snp_scaled_90%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance on Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian noise\n",
    "noise_alg = Gaussian\n",
    "means = [0]\n",
    "sigmas = list(range(0, 50, 5))\n",
    "noise_kwargs_pairs = make_grid_alg_kwargs(noise_alg, mean=means, sigma=sigmas)\n",
    "\n",
    "evaluations_g = benchmark(X_orl, Y_orl, scaler,\n",
    "                        alg_kwargs_pairs, all_n_components,\n",
    "                        noise_kwargs_pairs,\n",
    "                        metrics, metrics_names,\n",
    "                        n_trials, pc_sample\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations_g_mean = evaluations_g.groupby(['alg','n_components','noise_id']).mean()\n",
    "evaluationss_g_mean = evaluations_g_mean.rename(columns={'rre':'rre_mean','acc_score':'acc_mean','nmi_score':'nmi_mean'})\n",
    "evaluations_g_std = evaluations_g.groupby(['alg','n_components','noise_id']).std()\n",
    "evaluations_g_std = evaluations_g_std.rename(columns={'rre':'rre_sd','acc_score':'acc_sd','nmi_score':'nmi_sd'})\n",
    "evaluations_g_std = evaluations_g_std.drop(columns=['p', 'r'])\n",
    "evaluations_g_grouped = pd.concat([evaluations_g_mean, evaluations_g_std],axis=1)\n",
    "evaluations_g_grouped.to_csv('Performance_g_scaled_90%.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting RRE, Accuracy and NMI scores against different Gaussian noises for n_components=50\n",
    "fig = plt.figure(figsize=[9, 12])\n",
    "\n",
    "ax = fig.add_subplot(311)\n",
    "sns.lineplot(\n",
    "    x=\"p\",\n",
    "    y=\"rre\",\n",
    "    hue=\"alg\",\n",
    "    #size=\"n_components\",\n",
    "    style=\"alg\",\n",
    "    data=evaluations_g_grouped.query(\"n_components == 50 and (alg=='NmfL2Estimator' or alg=='NmfHyperEstimator' or alg=='NmfL1Estimator')\"),\n",
    "    estimator='mean',\n",
    "    ci=95,\n",
    "    n_boot=1000,\n",
    "    markers=True,\n",
    "    seed=None,\n",
    "    sort=True,\n",
    "    err_style='band',\n",
    "    #legend='full',\n",
    ")\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel(\"Relative Reconstruction Error\")\n",
    "#ax.legend(title=\"Algorithm\", loc=\"upper left\", labels=['NMF (sklearn)','L2-NMF','Hypersurface'])\n",
    "\n",
    "ax = fig.add_subplot(312)\n",
    "sns.lineplot(\n",
    "    x=\"p\",\n",
    "    y=\"acc_score\",\n",
    "    hue=\"alg\",\n",
    "    #size=\"n_components\",\n",
    "    style=\"alg\",\n",
    "    data=evaluations_g_grouped.query(\"n_components == 50 and (alg=='NmfL2Estimator' or alg=='NmfHyperEstimator' or alg=='NmfL1Estimator')\"),\n",
    "    estimator='mean',\n",
    "    ci=95,\n",
    "    n_boot=1000,\n",
    "    markers=True,\n",
    "    seed=None,\n",
    "    sort=True,\n",
    "    err_style='band',\n",
    "    legend='full',\n",
    ")\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel(\"Accuracy Score\")\n",
    "#ax.legend(title=\"Algorithm\", loc=\"upper right\", labels=['NMF (sklearn)','L2-NMF','Hypersurface'])\n",
    "\n",
    "ax = fig.add_subplot(313)\n",
    "sns.lineplot(\n",
    "    x=\"p\",\n",
    "    y=\"nmi_score\",\n",
    "    hue=\"alg\",\n",
    "    #size=\"n_components\",\n",
    "    style=\"alg\",\n",
    "    data=evaluations_g_grouped.query(\"n_components == 50 and (alg=='NmfL2Estimator' or alg=='NmfHyperEstimator' or alg=='NmfL1Estimator')\"),\n",
    "    estimator='mean',\n",
    "    ci=95,\n",
    "    markers=True,\n",
    "    n_boot=1000,\n",
    "    seed=None,\n",
    "    sort=True,\n",
    "    err_style='band',\n",
    "    legend='full',\n",
    ")\n",
    "ax.set_xlabel(\"Noise level\")\n",
    "ax.set_ylabel(\"Normalised Mutual Info Score\")\n",
    "#ax.legend(title=\"Algorithm\", loc=\"upper right\", labels=['NMF (sklearn)','L2-NMF','Hypersurface'])\n",
    "plt.suptitle(\"Model performances with Gaussian noise (using 50 components)\")\n",
    "plt.savefig(\"Gaussian_scaled_90%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
